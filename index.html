<!DOCTYPE html>
<html>
<head>
    <title>YOLOv8 Web VR (ONNX from GitHub)</title>
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
</head>
<body>
    <a-scene>
        <!-- 카메라 -->
        <a-camera position="0 1.6 0">
            <a-entity cursor="fuse: true; fuseTimeout: 1000"
                      geometry="primitive: ring; radiusInner: 0.02; radiusOuter: 0.03"
                      position="0 0 -1"
                      material="color: white; shader: flat">
            </a-entity>
        </a-camera>

        <!-- 웹캠 피드 표시 -->
        <a-assets>
            <video id="camera-feed" autoplay playsinline loop></video>
        </a-assets>
        <a-video src="#camera-feed" position="0 1.6 -3" width="4" height="3"></a-video>

        <!-- 배경 -->
        <a-sky color="#ECECEC"></a-sky>

        <!-- 추론 결과 표시 -->
        <a-entity id="detection-text" position="0 1 -3" text="value: Loading..."></a-entity>
    </a-scene>

    <script>
        // ONNX 모델 로드
        async function loadModel() {
            const modelURL = "https://jeongyakyoung.github.io/yolov8-web-vr/best.onnx"; // GitHub에서 모델 URL
            const session = await ort.InferenceSession.create(modelURL);
            console.log('Model loaded successfully');
            return session;
        }

        // 웹캠 초기화
        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { width: 640, height: 480 }
                });

                const video = document.querySelector("#camera-feed");
                video.srcObject = stream;

                video.onloadedmetadata = () => {
                    video.play();
                    console.log("Webcam successfully connected!");
                };

                return video;
            } catch (error) {
                console.error("Failed to access the webcam:", error);
                alert("Webcam access is required. Please check your browser settings.");
            }
        }

        // YOLO 추론
            async function detectObjects(session, video) {
            const canvas = document.createElement('canvas');
            canvas.width = 640; // YOLO 모델이 기대하는 정사각형 크기
            canvas.height = 640;
            const ctx = canvas.getContext('2d');

            // Draw the video frame onto the canvas
            ctx.drawImage(video, 0, 0, 640, 640);

            // Get image data from the canvas
            const imageData = ctx.getImageData(0, 0, 640, 640);
            const input = new Float32Array(640 * 640 * 3); // YOLO expects RGB data

            // Convert RGBA to RGB and normalize the values
            for (let i = 0; i < 640 * 640; i++) {
                const offset = i * 4; // RGBA channels in imageData
                input[i] = imageData.data[offset] / 255.0; // Red
                input[i + 640 * 640] = imageData.data[offset + 1] / 255.0; // Green
                input[i + 2 * 640 * 640] = imageData.data[offset + 2] / 255.0; // Blue
            }

            // Create a tensor for the ONNX model
            const tensor = new ort.Tensor('float32', input, [1, 3, 640, 640]);

            // Run the model and get results
            const results = await session.run({ images: tensor });

            // Debug: Log raw results
            console.log('Raw results:', results);

            // Parse YOLOv8 ONNX model output
            const output = results.output0.data;
            const numDetections = output.length / 6; // Assuming each detection has 6 values [x, y, w, h, score, class]

            const boxes = [];
            const scores = [];
            const classes = [];

            for (let i = 0; i < numDetections; i++) {
                const offset = i * 6;
                const [x, y, w, h, score, classID] = output.slice(offset, offset + 6);

                if (score > 0.5) { // Only consider detections with confidence > 0.5
                    boxes.push([x, y, w, h]);
                    scores.push(score);
                    classes.push(classID);
                }
            }

            // Debug: Log parsed results
            console.log('Boxes:', boxes, 'Scores:', scores, 'Classes:', classes);

            return { boxes, scores, classes };
        }

        
        // 메인 실행
        async function main() {
            const session = await loadModel(); // GitHub에서 ONNX 모델 로드
            const video = await setupCamera(); // 웹캠 초기화

            if (!video) {
                console.error("Webcam initialization failed. Exiting...");
                return;
            }

            const detectionText = document.querySelector('#detection-text');

            async function processFrame() {
                const results = await detectObjects(session, video);

                // Parse results
                const boxes = results.boxes?.data || []; // 바운딩 박스 좌표
                const scores = results.scores?.data || []; // 신뢰도
                const classes = results.classes?.data || []; // 클래스 ID

                // Debug: Log parsed results
                console.log('Boxes:', boxes, 'Scores:', scores, 'Classes:', classes);

                // Update detection text
                detectionText.setAttribute('text', `value: Detected: ${classes.length} objects`);

                // 다음 프레임 처리
                requestAnimationFrame(processFrame);
            }

            processFrame();
        }

        document.addEventListener("DOMContentLoaded", () => {
            console.log("Page loaded, initializing YOLO...");
            main().then(() => {
                console.log("YOLO is running.");
            }).catch((error) => {
                console.error("Error in YOLO initialization:", error);
            });
        });
    </script>
</body>
</html>
